use anyhow::{anyhow, Result};
use polars::prelude::*;
use pyo3::prelude::*;
use pyo3::types::PyDict;
use pyo3::{Bound, PyRefMut};
use pyo3_polars::PyDataFrame;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use tokio::process::Command;

/// Hiveè¿æ¥é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
#[pyclass]
pub struct HiveConfig {
    #[pyo3(get, set)]
    pub host: String,
    #[pyo3(get, set)]
    pub port: u16,
    #[pyo3(get, set)]
    pub username: String,
    #[pyo3(get, set)]
    pub database: String,
    #[pyo3(get, set)]
    pub auth: String,
}

#[pymethods]
impl HiveConfig {
    #[new]
    fn new(
        host: Option<String>,
        port: Option<u16>,
        username: Option<String>,
        database: Option<String>,
        auth: Option<String>,
    ) -> Self {
        Self {
            host: host.unwrap_or_else(|| "localhost".to_string()),
            port: port.unwrap_or(10000),
            username: username.unwrap_or_else(|| "default".to_string()),
            database: database.unwrap_or_else(|| "default".to_string()),
            auth: auth.unwrap_or_else(|| "NONE".to_string()),
        }
    }

    fn __repr__(&self) -> String {
        let host = &self.host;
        let port = self.port;
        let username = &self.username;
        let database = &self.database;
        let auth = &self.auth;
        format!("HiveConfig(host='{host}', port={port}, username='{username}', database='{database}', auth='{auth}')")
    }
}

/// Rustç‰ˆæœ¬çš„Hiveæ•°æ®è¯»å–å™¨
#[derive(Debug)]
#[pyclass]
pub struct RustHiveReader {
    config: HiveConfig,
    connected: bool,
}

#[pymethods]
impl RustHiveReader {
    #[new]
    fn new(config: Option<HiveConfig>) -> Self {
        let config = config.unwrap_or_else(|| HiveConfig::new(None, None, None, None, None));
        Self {
            config,
            connected: false,
        }
    }

    /// è¿æ¥åˆ°Hive
    fn connect(&mut self) -> PyResult<()> {
        let host = &self.config.host;
        let port = self.config.port;
        println!("ğŸ”— è¿æ¥åˆ°Hive: {host}:{port}");

        // è¿™é‡Œå®ç°å®é™…çš„è¿æ¥é€»è¾‘
        // ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿè¿æ¥æˆåŠŸ
        self.connected = true;
        println!("âœ… Hiveè¿æ¥æˆåŠŸ (Rustç‰ˆæœ¬)");
        Ok(())
    }

    /// æ–­å¼€è¿æ¥
    fn disconnect(&mut self) -> PyResult<()> {
        if self.connected {
            println!("ğŸ”Œ æ–­å¼€Hiveè¿æ¥");
            self.connected = false;
        }
        Ok(())
    }

    /// æ£€æŸ¥è¿æ¥çŠ¶æ€
    fn is_connected(&self) -> bool {
        self.connected
    }

    /// æ‰§è¡ŒSQLæŸ¥è¯¢å¹¶è¿”å›Polars DataFrame
    fn query_to_polars(&self, sql: String) -> PyResult<PyDataFrame> {
        if !self.connected {
            return Err(PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
                "æœªè¿æ¥åˆ°Hiveï¼Œè¯·å…ˆè°ƒç”¨connect()",
            ));
        }

        let preview = &sql[..std::cmp::min(sql.len(), 50)];
        println!("ğŸ” æ‰§è¡ŒSQLæŸ¥è¯¢: {preview}");

        // è¿™é‡Œè°ƒç”¨å®é™…çš„æŸ¥è¯¢å®ç°
        let df = self
            .execute_sql_query(&sql)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(e.to_string()))?;

        Ok(PyDataFrame(df))
    }

    /// æ˜¾ç¤ºæ‰€æœ‰è¡¨
    fn show_tables(&self) -> PyResult<PyDataFrame> {
        self.query_to_polars("SHOW TABLES".to_string())
    }

    /// æè¿°è¡¨ç»“æ„
    fn describe_table(&self, table_name: String) -> PyResult<PyDataFrame> {
        let sql = format!("DESCRIBE {table_name}");
        self.query_to_polars(sql)
    }

    /// è·å–è¡¨æ ·æœ¬æ•°æ®
    fn get_table_sample(&self, table_name: String, limit: Option<i32>) -> PyResult<PyDataFrame> {
        let limit = limit.unwrap_or(10);
        let sql = format!("SELECT * FROM {table_name} LIMIT {limit}");
        self.query_to_polars(sql)
    }

    /// è·å–é…ç½®ä¿¡æ¯
    fn get_config(&self) -> HiveConfig {
        self.config.clone()
    }
}

impl RustHiveReader {
    /// æ‰§è¡ŒSQLæŸ¥è¯¢çš„å†…éƒ¨å®ç°
    fn execute_sql_query(&self, sql: &str) -> Result<DataFrame> {
        // æ–¹æ¡ˆ1: ä½¿ç”¨beelineå‘½ä»¤è¡Œå®¢æˆ·ç«¯
        if std::env::var("USE_BEELINE").unwrap_or_default() == "true" {
            return self.execute_via_beeline(sql);
        }

        // æ–¹æ¡ˆ2: æ¨¡æ‹Ÿæ•°æ®ï¼ˆç”¨äºæ¼”ç¤ºå’Œæµ‹è¯•ï¼‰
        self.execute_mock_query(sql)
    }

    /// é€šè¿‡beelineæ‰§è¡ŒæŸ¥è¯¢
    fn execute_via_beeline(&self, sql: &str) -> Result<DataFrame> {
        let rt = tokio::runtime::Runtime::new()?;
        rt.block_on(async {
            let host = &self.config.host;
            let port = self.config.port;
            let database = &self.config.database;
            let jdbc_url = format!("jdbc:hive2://{host}:{port}/{database}");

            let output = Command::new("beeline")
                .args([
                    "-u",
                    &jdbc_url,
                    "-e",
                    sql,
                    "--outputformat=csv2",
                    "--silent=true",
                ])
                .output()
                .await?;

            if !output.status.success() {
                let error = String::from_utf8_lossy(&output.stderr);
                return Err(anyhow!("Beelineæ‰§è¡Œå¤±è´¥: {error}"));
            }

            let csv_data = String::from_utf8_lossy(&output.stdout);
            self.parse_csv_to_dataframe(&csv_data)
        })
    }

    /// æ¨¡æ‹ŸæŸ¥è¯¢æ‰§è¡Œï¼ˆç”¨äºæ¼”ç¤ºï¼‰
    fn execute_mock_query(&self, sql: &str) -> Result<DataFrame> {
        println!("ğŸ“Š æ¨¡æ‹Ÿæ‰§è¡ŒSQL: {sql}");

        // æ ¹æ®SQLç±»å‹è¿”å›ä¸åŒçš„æ¨¡æ‹Ÿæ•°æ®
        if sql.to_uppercase().contains("SHOW TABLES") {
            self.create_mock_tables_df()
        } else if sql.to_uppercase().contains("DESCRIBE") {
            self.create_mock_describe_df()
        } else if sql.to_uppercase().contains("SELECT") {
            self.create_mock_select_df(sql)
        } else {
            Err(anyhow!("ä¸æ”¯æŒçš„SQLç±»å‹"))
        }
    }

    /// åˆ›å»ºæ¨¡æ‹Ÿè¡¨åˆ—è¡¨
    fn create_mock_tables_df(&self) -> Result<DataFrame> {
        let tables = vec![
            "users".to_string(),
            "orders".to_string(),
            "products".to_string(),
            "analytics".to_string(),
            "logs".to_string(),
        ];

        let df = df! {
            "tab_name" => tables,
        }?;

        Ok(df)
    }

    /// åˆ›å»ºæ¨¡æ‹Ÿè¡¨ç»“æ„æè¿°
    fn create_mock_describe_df(&self) -> Result<DataFrame> {
        let df = df! {
            "col_name" => vec!["id", "name", "created_at", "status"],
            "data_type" => vec!["bigint", "string", "timestamp", "string"],
            "comment" => vec!["Primary key", "User name", "Creation time", "Record status"],
        }?;

        Ok(df)
    }

    /// åˆ›å»ºæ¨¡æ‹ŸæŸ¥è¯¢ç»“æœ
    fn create_mock_select_df(&self, sql: &str) -> Result<DataFrame> {
        // æ ¹æ®SQLç”Ÿæˆä¸åŒçš„æ¨¡æ‹Ÿæ•°æ®
        if sql.to_uppercase().contains("COUNT") {
            df! {
                "count" => vec![1000i64, 2000, 3000],
                "table_name" => vec!["table1", "table2", "table3"],
            }
            .map_err(|e| anyhow!("åˆ›å»ºDataFrameå¤±è´¥: {e}"))
        } else {
            // é€šç”¨çš„ç¤ºä¾‹æ•°æ®
            df! {
                "id" => vec![1i64, 2, 3, 4, 5],
                "name" => vec!["Alice", "Bob", "Charlie", "David", "Eve"],
                "score" => vec![95.5, 87.2, 92.1, 78.9, 88.7],
                "created_at" => vec![
                    "2025-01-01 10:00:00",
                    "2025-01-02 11:00:00",
                    "2025-01-03 12:00:00",
                    "2025-01-04 13:00:00",
                    "2025-01-05 14:00:00",
                ],
            }
            .map_err(|e| anyhow!("åˆ›å»ºDataFrameå¤±è´¥: {e}"))
        }
    }

    /// è§£æCSVæ•°æ®ä¸ºDataFrame
    fn parse_csv_to_dataframe(&self, csv_data: &str) -> Result<DataFrame> {
        // è¿™é‡Œå®ç°CSVè§£æé€»è¾‘
        // ä¸ºç®€å•èµ·è§ï¼Œè¿™é‡Œè¿”å›ä¸€ä¸ªç¤ºä¾‹DataFrame
        let df = df! {
            "data" => vec![csv_data],
        }?;
        Ok(df)
    }
}

/// ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ”¯æŒ
#[pyclass]
pub struct RustHiveContext {
    reader: RustHiveReader,
}

#[pymethods]
impl RustHiveContext {
    #[new]
    fn new(config: Option<HiveConfig>) -> Self {
        Self {
            reader: RustHiveReader::new(config),
        }
    }

    fn __enter__(mut slf: PyRefMut<'_, Self>) -> PyResult<PyRefMut<'_, Self>> {
        slf.reader.connect()?;
        Ok(slf)
    }

    fn __exit__(
        &mut self,
        _exc_type: Option<&Bound<'_, PyAny>>,
        _exc_value: Option<&Bound<'_, PyAny>>,
        _traceback: Option<&Bound<'_, PyAny>>,
    ) -> PyResult<bool> {
        self.reader.disconnect()?;
        Ok(false) // ä¸æŠ‘åˆ¶å¼‚å¸¸
    }
}

/// ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºHiveé…ç½®
#[pyfunction]
fn create_hive_config(
    host: Option<String>,
    port: Option<u16>,
    username: Option<String>,
    database: Option<String>,
    auth: Option<String>,
) -> HiveConfig {
    HiveConfig::new(host, port, username, database, auth)
}

/// ä¾¿æ·å‡½æ•°ï¼šä»å­—å…¸åˆ›å»ºé…ç½®
#[pyfunction]
fn config_from_dict(config_dict: &Bound<'_, PyDict>) -> PyResult<HiveConfig> {
    let host = config_dict
        .get_item("host")?
        .map(|v| v.extract::<String>())
        .transpose()?;
    let port = config_dict
        .get_item("port")?
        .map(|v| v.extract::<u16>())
        .transpose()?;
    let username = config_dict
        .get_item("username")?
        .map(|v| v.extract::<String>())
        .transpose()?;
    let database = config_dict
        .get_item("database")?
        .map(|v| v.extract::<String>())
        .transpose()?;
    let auth = config_dict
        .get_item("auth")?
        .map(|v| v.extract::<String>())
        .transpose()?;

    Ok(HiveConfig::new(host, port, username, database, auth))
}

/// æ€§èƒ½åŸºå‡†æµ‹è¯•å‡½æ•°
#[pyfunction]
fn benchmark_query(
    config: HiveConfig,
    sql: String,
    iterations: Option<usize>,
) -> PyResult<HashMap<String, f64>> {
    let iterations = iterations.unwrap_or(10);
    let mut reader = RustHiveReader::new(Some(config));
    reader.connect()?;

    let start = std::time::Instant::now();

    for _ in 0..iterations {
        let _result = reader.query_to_polars(sql.clone())?;
    }

    let duration = start.elapsed();
    let avg_time = duration.as_secs_f64() / iterations as f64;

    reader.disconnect()?;

    let mut results = HashMap::new();
    results.insert("total_time".to_string(), duration.as_secs_f64());
    results.insert("average_time".to_string(), avg_time);
    results.insert("iterations".to_string(), iterations as f64);
    results.insert(
        "queries_per_second".to_string(),
        iterations as f64 / duration.as_secs_f64(),
    );

    Ok(results)
}

/// Pythonæ¨¡å—å®šä¹‰
#[pymodule]
fn hive_reader_rs(_py: Python, m: &Bound<'_, PyModule>) -> PyResult<()> {
    // ç±»
    m.add_class::<HiveConfig>()?;
    m.add_class::<RustHiveReader>()?;
    m.add_class::<RustHiveContext>()?;

    // å‡½æ•°
    m.add_function(wrap_pyfunction!(create_hive_config, m)?)?;
    m.add_function(wrap_pyfunction!(config_from_dict, m)?)?;
    m.add_function(wrap_pyfunction!(benchmark_query, m)?)?;

    // ç‰ˆæœ¬ä¿¡æ¯
    m.add("__version__", "0.1.0")?;
    m.add("__author__", "Hive Reader Rust")?;

    Ok(())
}
